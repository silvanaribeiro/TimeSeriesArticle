{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook applies PCA to every Imputed and Enriched data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file):\n",
    "    print(file)\n",
    "    df = pd.read_csv(file, parse_dates=True, index_col=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(df):\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    scaler.fit(df)\n",
    "    array = scaler.transform(df)\n",
    "    df_scaled = pd.DataFrame(data=array, index=df.index, columns=df.columns)\n",
    "    return df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descaler(df, scaler):\n",
    "    array = scaler.inverse_transform(df)\n",
    "    df_final = pd.DataFrame(data=array, index=df.index, columns=df.columns)\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_number_components(df):\n",
    "    pca = PCA(svd_solver='full')\n",
    "    pca.fit(df)\n",
    "    pca.explained_variance_ratio_\n",
    "    explained_var = 0\n",
    "    num_components = 0\n",
    "    for var in pca.explained_variance_ratio_:\n",
    "        explained_var += var\n",
    "        num_components +=1\n",
    "        if explained_var >=0.95:\n",
    "            break\n",
    "\n",
    "    print(explained_var, \" is the percentage of variance explained by \", num_components, \" components.\")\n",
    "    return num_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(df, df_test, num_components):\n",
    "    pca = PCA(n_components=num_components)\n",
    "    pca.fit(df)\n",
    "    principalComponents = pca.transform(df)\n",
    "    principalDf = pd.DataFrame(data = principalComponents)\n",
    "    principalComponents_test = pca.transform(df_test)\n",
    "    principalDf_test = pd.DataFrame(data = principalComponents_test)\n",
    "    return principalDf, principalDf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNNWeeklyImputed_training_FE.csv\n",
      "KNNWeeklyImputed_test_FE.csv\n",
      "0.9511360058248994  is the percentage of variance explained by  80  components.\n",
      "___________________\n",
      "MeanWeeklyImputed_training_FE.csv\n",
      "MeanWeeklyImputed_test_FE.csv\n",
      "0.9503438554151121  is the percentage of variance explained by  92  components.\n",
      "___________________\n",
      "MIIWeeklyImputed_training_FE.csv\n",
      "MIIWeeklyImputed_test_FE.csv\n",
      "0.9501726005056654  is the percentage of variance explained by  27  components.\n",
      "___________________\n",
      "MovingAverageWeeklyImputed_training_FE.csv\n",
      "MovingAverageWeeklyImputed_test_FE.csv\n",
      "0.9501059524334041  is the percentage of variance explained by  64  components.\n",
      "___________________\n",
      "RegressionWeeklyImputed_training_FE.csv\n",
      "RegressionWeeklyImputed_test_FE.csv\n",
      "0.951722703764459  is the percentage of variance explained by  57  components.\n",
      "___________________\n"
     ]
    }
   ],
   "source": [
    "files = ['KNNWeeklyImputed','MeanWeeklyImputed', 'MIIWeeklyImputed', 'MovingAverageWeeklyImputed', 'RegressionWeeklyImputed']\n",
    "for file in files:\n",
    "    df = read_csv(file+'_training_FE.csv')\n",
    "    df_test = read_csv(file+'_test_FE.csv')\n",
    "    df_scaled = scale(df)\n",
    "    df_test_scaled = scale(df_test)\n",
    "    \n",
    "    num_components = calculate_number_components(df_scaled)\n",
    "    print(\"___________________\")\n",
    "    principalDf, testDf = apply_pca(df_scaled, df_test_scaled, num_components)\n",
    "    principalDf.to_csv(file + '_PCA_training_FE.csv', index = True)\n",
    "    testDf.to_csv(file + '_PCA_test_FE.csv', index = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
